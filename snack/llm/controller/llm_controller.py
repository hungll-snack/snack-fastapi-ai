# llm_controller.py
from fastapi import APIRouter, Request, Depends, Header
from fastapi.responses import StreamingResponse
from llm.service.llm_service_impl import LLMServiceImpl
from llm.service.prompt_builder import PromptBuilder
from weather.service.weather_service_impl import WeatherServiceImpl
import requests
import os

llmRouter = APIRouter()

def fetch_user_preference(account_id):
    base_url = os.getenv("DJANGO_BASE_URL", "http://localhost:8000")
    url = f"{base_url}/account-prefer/{account_id}"
    print(f"[DEBUG] ìš”ì²­ URL: {url}")
    response = requests.get(url)
    return response.json() if response.status_code == 200 else None

@llmRouter.post("/llm/search")
async def search_llm(
    request: Request,
    usertoken: str = Header(...),
    account_id: str = Header(...),
    llmService: LLMServiceImpl = Depends(LLMServiceImpl),
):
    data = await request.json()
    query = data.get("query")

    if not query or not account_id:
        return StreamingResponse(
            content=iter(["[ì˜¤ë¥˜] query ë˜ëŠ” account_idê°€ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤."]),
            media_type="text/plain"
        )

    prefer = fetch_user_preference(account_id)
    if not prefer:
        print(f"[ê²½ê³ ] account_id={account_id}ì˜ ì„ í˜¸ë„ ì •ë³´ ì—†ìŒ â€” ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ë¡œ ì§„í–‰")
        prefer = {}

    weather = WeatherServiceImpl().get_seoul_weather()
    builder = PromptBuilder(prefer_model=prefer, weather=weather)
    prompt = builder.build_prompt(query)

    stream = llmService.get_streaming_openai_response(prompt)

    def generate():
        for chunk in stream:
            try:
                print("ğŸ”¹ sending:", chunk.content)
                yield chunk.content
            except Exception as e:
                print(f"âŒ ìŠ¤íŠ¸ë¦¬ë° ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
                continue

    return_response = StreamingResponse(generate(), media_type="text/plain")
    return_response.headers["Access-Control-Expose-Headers"] = "usertoken, account-id, authorization, transfer-encoding"
    return_response.headers["transfer-encoding"] = "chunked"
    return_response.headers["Content-Type"] = "text/event-stream"
    return_response.headers["Cache-Control"] = "no-cache"

    return return_response
