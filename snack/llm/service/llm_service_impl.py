from openai import OpenAI
import os
from rag.embedder import get_embedding
from rag.faiss_index import search

class LLMServiceImpl:
    def __init__(self):
        self.client = OpenAI(
            api_key=os.getenv("OPENAI_API_KEY"),
            timeout=10  # âœ… ì—¬ê¸°ì„œ timeout ì„¤ì •
        )

    def get_response_from_openai(self, prompt: str) -> str:
        #rag
        query_embedding = get_embedding(prompt)
        similar_restaurants = search(query_embedding)

        extra_context = "\n".join([
            f"{r['name']} ({r['address']}) í‰ì : {r['rating']}" for r in similar_restaurants
        ])
        #ì—¬ê¸°ë¶€í„´ prompt
        prompt += f"\nğŸ“ ê´€ë ¨ ë§›ì§‘ ì •ë³´:\n{extra_context}"

        print(f"ğŸ” í”„ë¡¬í”„íŠ¸:\n{prompt}")
        try:
            response = self.client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[{"role": "user", "content": prompt}],
                temperature=0.7,
                stream=True
            )
            result = response.choices[0].message.content
            print(f"âœ… ì‘ë‹µ ê²°ê³¼: {result}")
            return result
        except Exception as e:
            print(f"âŒ OpenAI í˜¸ì¶œ ì‹¤íŒ¨: {e}")
            return "ë¯¸ì•ˆí•´ìš”! í—ê¸€ì´ ë”±ë§ëŠ” ëŒ€ë‹µì„ ì°¾ê¸°ìœ„í•´ ì•Œì•„ë³´ê³ ìˆì–´ìš” ğŸ’¡"
